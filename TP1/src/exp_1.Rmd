---
title: "exp_1"
author: "Patricio Guledjian, Azul Noguera, Rocio Gonzalez"
date: "`r Sys.Date()`"
output: html_document
---

```{r}
source("exp_1.R")
```

```{r}

library(magick)

# Ruta de la imagen JPG
ruta_imagen <- "./outputs/plots/exp_1.jpg"

# Cargar y mostrar la imagen
imagen <- image_read(ruta_imagen)
# Redimensionar la imagen para ajustarla al tamaño de la consola
imagen_redimensionada <- image_scale(imagen, "475x500")

# Mostrar la imagen redimensionada en la consola
print(imagen_redimensionada)

```
Hicimos este código para que la tabla con los experimentos se pueda ver en pantalla a medida que les contamos sobre nuestras observaciones y así resulte más fácil seguir lo que decimos.

En este experimento probamos con distintos valores de proporción de NA, en cada uno de nuestros datasets. Hicimos observaciones entre distintos datasets como tambien entre distintas etapas de un mismo dataset. Comencemos con las observaciones:

- En primer lugar, podemos ver un patrón muy claro en donde los datasets llegan a sus picos de performance en profundidades más chicas (con prop_NA=0.1, llegan al pico con max_depth=4/5), y luego con profundidades más grandes el AUC comienza a reducir. En particular, el dataset de Heart y el de Wine tienden a llegar a un pico y luego bajar su performance de manera empinada. Esto puede ser causado por particulares de estos dos datasets, o tambien por overfitting. Esto significa que el árbol esta captando mucho detalle; al ser tan profundo es muy específico y cuando lo llevo a datos desconocidos no performa bien.

- Otra observación general, que puede ser obvia pero no está de más aclarar, es que los picos de performance de prop_NAs tienen, en este caso, la relación donde el pico de un prop_NA menor es mayor al pico de un prop_NA mayor. Tiene sentido ya que, a mayor cantidad de NAs, es más difícil para el árbol conseguir una performance alta. Por lo tanto, el 20% más de datos que tienen los prop_NA más chicos que sus siguientes, ayudan a que el árbol consiga una mayor performance.

- Una característica que varia entre los distintos datasets es la distancia que cada uno tiene entre las dos líneas. La roja significa que r-part usa su propia estrategia para imputar a los datos faltantes, y la azul significa que le imputamos la media/moda, dependiendo la variable, a los datos faltantes. Vemos que cada dataset parecería estar un caso distinto, ya que en uno la línea roja siempre es superior a la azul, en otro caso son muy parecidas, y en el último la azul es superior.

Veamos uno por uno:
    . Churn: En el caso del dataset de customer_churn, se visualiza que la línea roja supera a la azul en la mayoría        de los casos. Esto significa que la media/moda que imputamos en los datos faltantes no está resultando en lo           mejor, y puede ser consecuencia, por ejemplo, de outliers. Estos valores extremos afectan en general a la media.
    . Heart: En el caso del dataset de heart, observamos un caso intermedio, donde las líneas se mantienen muy            parecidas, con distintos momentos en los que una supera a la otra. Estos comportamientos pueden estar atribuidos a la particularidad de los datos.
    . Wine: Finalmente, el caso del dataset de winequality, podemos ver un comportamiento distinto a lo que pasaba con       los otros datasets, ya que la línea azul a medida que aumenta el prop_NA, comienza a tener mejores perfomances que la línea roja. Esto ocurre porque es un dataset que no contiene muchos outliers, y por lo tanto, la media imputada en los datos faltantes, es muy buena. Entonces, que hayan muchos datos faltantes le afecta más a r-part y su estrategia propia que a nosotros que hacemos uso de la media y en general nunca nos alejamos mucho de la media real.

- Otras particularidades y diferencias entre los datasets son sus valores. Al principio con 1 de profundidad, en su pico de performance, y al final con 30 de profundidad. En el caso de profundidad 1, el que mayor valor tiene es el arbol del dataset Heart con un AUC de 0.8, cuando Wine y Churn tienen 0.6 y 0.65 respectivamente. Esto es una particularidad del dataset, como tambien que en Churn se alcanza el pico mas alto, con 0.9. Finalmente, con un prop_NA de 0.9, todos los datasets tienen performance muy bajas y tiene sentido porque se les sacó el 90% de los datos. 











































